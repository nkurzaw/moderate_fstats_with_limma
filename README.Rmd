---
title: "Using limma::squeezeVar() to moderate *F*-statistics"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We start by loading the `limma` library:

```{r loadLibs}
library(limma)
```

Then, we define some arbitrary values for our degrees of freedom, sample sizes and values used for plotting.

```{r setParams}
df_1 <-  14
df_2 <- 26
n <- 5000
xg <- seq(0, 120, by = 0.05)
```

Next, we generate random $\chi^{2}$ distributed data with the above choosen degrees of freedom.

```{r getRandomChiSqdata}
set.seed(12)
chi_sq_numerator <- rchisq(n, df = df_1)
chi_sq_denominator <- rchisq(n, df = df_2)
```

To check that we actually got $\chi^{2}$ distributed data with the respective degrees of freedom, we check their distributions.

```{r inspectNumerator}
hist(chi_sq_numerator, breaks = 100, probability = TRUE)
lines(xg, dchisq(xg, df = df_1), col = "red")
```

```{r inspectDenominator}
hist(chi_sq_denominator, breaks = 100, probability = TRUE)
lines(xg, dchisq(xg, df = df_2), col = "red")
```
Now, we compute our $F$-statistics with $F = \frac{\chi^2_{1}}{\chi^2_{2}} \frac{d_{2}}{d_{1}}$:
```{r computeF}
f_standard <- (chi_sq_numerator/df_1)/(chi_sq_denominator/df_2)
```

and inspect if our data is distributed as expected:

```{r inspectF}
hist(f_standard, breaks = 100, probability = TRUE)
lines(xg, df(xg, df1 = df_1, df2 = df_2), col = "red")
```

Now, we would like to obtain more precise estimators $\widetilde{s}^2_{i}$ for our true $\sigma^2_{i} = \frac{\chi^2_{2}_{i}}{d_{2}}$ and ultimately obtain a partially moderated $F$-statistic. To achieve that, we phrase our problem as a Bayesian estimation of the variance of a Normal distribution around a  known mean $\mu$ and use all observed variances $s^2$ to shrink individual estimates $s^2_{i}$ towards $\text{E}[s^2]$. In order to do so, we assume that the true $\sigma^2$ follows a scaled inverse $\chi^2$ distribution, or if we consider $\frac{1}{\sigma^2}$:
$$\frac{1}{\sigma^2} \sim \frac{1}{d_{0}s_{0}^2} \chi^{2}$$
Using Bayes' theorem it can be derived that the posterior mean $\widetilde{s}^2_{i}$ of this model can be computed with
$$\widetilde{s}^2_{i} = \frac{d_{0}s^2_{0} + d_{2}s^2_{i}}{d_{0} + d_{g}$$.

The hyperparameters $s^2_{0}$ and $d_{0}$ can be computed by fitting $s^2$ as a scaled $F$-distriubtion with
$$s^2 \sim s^2_{0}F_{d, d_{0}}$$.
Details on the parameter estimation are described by Smyth et al. (2004) and implemented within the `limma` R package in the function `squeezeVar()`.

We perform the above described moderation by calling `limma::squeezeVar()`:
```{r squeezeVar}
chi_sq_denominator_squeezeVar <- squeezeVar(chi_sq_denominator/df_2, df = df_2)
df_0 <- chi_sq_denominator_squeezeVar$df.prior
squeezed_chi_sq_denominator <- chi_sq_denominator_squeezeVar$var.post
```

Since our estimated $\widetilde{s}^2_{i}$ is already scaled by its posterior degrees of freedom $\widetilde{d}_{2} = d_{0} + d_{2}$, our moderated $F$-statistic is computed by

```{r computeModF}
f_moderated <- (chi_sq_numerator/df_1)/(squeezed_chi_sq_denominator)
```

We inspect our moderated $F$ distribution
```{r inspectModF}
hist(f_moderated, breaks = 100, probability = TRUE)
lines(xg, df(xg, df1 = df_1, df2 = df_0 + df_2), col = "red")
```
If we where to obtain $p$-values now, these would be distributed as follows:
```{r inspectPs}
pvals <- 1 - pf(f_moderated, df1 = df_1, df2 = df_0 + df_2)
hist(pvals, breaks = 12)
abline(h = n/10, col="black", lwd=3, lty=2)
```

```{r}
sessionInfo()
```

